p8105_hw2_dc3964
================
Rene Chi
2025-09-24

``` r
### loading packages
library(tidyverse)
library(lubridate)
library(readxl)
```

## Problem 1

``` r
## Problem 1
### tidying pol-month
pols_month =
  read_csv("./data/pols-month.csv") |> 
  separate(mon, c("year", "month", "day")) |> 
  mutate(month = month.abb[as.integer(month)]) |> 
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem",
    TRUE          ~ NA_character_
  )) |> 
  select(-day, -prez_gop, -prez_dem)

### tidying snp
snp = 
  read_csv("./data/snp.csv") |> 
  separate(date, c("month", "day", "year")) |> 
  select(year, month, everything()) |> 
  select(-day) |> 
  mutate(across(c(month:year), as.integer)) |> 
  mutate(month = factor(month.name[month], levels = month.name)) |> 
  ## changed format from 2 digit to 4 digit 
  mutate(year = if_else(as.integer(year) <= 15,
                          2000 + as.integer(year),
                          1900 + as.integer(year))) |> 
  ## changed format from integer to character
  mutate(year = as.character(year)) |> 
  select(year, month, everything()) |> 
  arrange(year, month)

### tidying unemployment
unemployment =
  read_csv("./data/unemployment.csv") |> 
  rename(year = Year) |> 
  mutate(year = as.character(year)) |> 
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemployment_rate")

### Merging all datasets
partial_complete_p1 = left_join(pols_month, snp) 
complete_data_p1 = left_join(partial_complete_p1, unemployment)
```

### **Data description**

Pols-month has 822 rows and 9 variables, with the years ranged from 1947
to 2015. Key variables being year and month for data merging.

Snp has 787 rows and 3 variables, with the years ranged from 1950 to
2015. Key variables being year and month for data merging.

Unemployment has 816 rows and 3 variables, with the years ranged from
1948 to 2015. Key variables being year and month for data merging.

The merged data set has 822 rows and 11 columns, with the years ranged
from 1947 to 2015. Key variables being year and month as I used them to
merge all of the data sets.

## Problem 2

``` r
mr_trashwheel =
  read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             range = "A2:N710",
             na = c("")
             ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = as.integer(round(sports_balls))) |>
  mutate(wheel_tag = "mr")

professor_trashwheel =
  read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             range = "A2:M135", 
             na = c("")
             ) |> 
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(year = as.character(year)) |> 
  mutate(wheel_tag = "professor")

gwynnda_trashwheel =
  read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel",
             range = "A2:L352",
             na = c("")
             ) |> 
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(year = as.character(year)) |> 
  mutate(wheel_tag = "gwynnda")

partial_complete_p2 = full_join(mr_trashwheel, professor_trashwheel)
complete_data_p2 = full_join(partial_complete_p2, gwynnda_trashwheel) |> 
  select(wheel_tag, everything())

### Total weight of trash collected by Professor Trash Wheel
complete_data_p2 |> 
  filter(wheel_tag == "professor") |>   
  pull(weight_tons) |>                   
  sum()      

### Total number of cigarette butts collected by Gwynnda in June of 2022
complete_data_p2 |> 
  filter(wheel_tag == "gwynnda", month == "June", year == "2022") |>   
  pull(cigarette_butts) |>                   
  sum() ## note that in the rmd file I changed the code a bit
        ## just to get rid of scientific symbol
```

### **Data description**

mr_trashwheel has 707 rows and 15 variables, with the years ranged from
2014 to 2024. Key variables being the wheel tag as it is the column to
distinguish different trash wheels.

professor_trashwheel has 132 rows and 14 variables, with the years
ranged from 2017 to 2024. Key variables being the wheel tag as it is the
column to distinguish different trash wheels.

gwynnda_trashwheel has 349 rows and 13 variables, with the years ranged
from 2021 to 2024. Key variables being the wheel tag as it is the column
to distinguish different trash wheels.

complete_data_p2 has 1188 observations and 15 variables, with the years
ranged from 2014 to 2025. Key variables being the wheel tag as it is the
column to distinguish different trash wheels.

The total weight of trash collected by Professor Trash Wheel is 282.26
tons. Meanwhile, the total number of cigarette butts collected by
Gwynnda in June of 2022 is 18,120

## Problem 3

``` r
## Problem 3
zip_codes = 
  read_csv("./data/Zip Codes.csv") |> 
  janitor::clean_names()

zip_zillow =
  read_csv("./data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  pivot_longer(
    cols = matches("^\\d{4}-\\d{1,2}-\\d{1,2}$"), 
    names_to = "date",
    values_to = "zori"
  ) |> 
  janitor::clean_names() |> 
  rename(zip_code = region_name)

complete_data_p3 = left_join(zip_codes, zip_zillow,
                             relationship = "many-to-many") |> 
  select(zip_code, county_name, date, zori, everything())
```

The observation number for the merged data set is 17687, with 320 unique
zip codes and 43 unique neighborhoods.

``` r
unique_zips =
  anti_join(zip_codes, zip_zillow, by = "zip_code") |>
  arrange(zip_code)
```

There are 171 zip codes appear in the ZIP code data set but not in the
Zillow Rental Price data set. I believe the main reason is, the zip
codes not included in the zillow rental price data set might be inside a
commercial or an industrial area.

``` r
covid_19 =
  complete_data_p3 |> 
  select(zip_code, date, zori, county, neighborhood) |> 
  filter(date %in% c("2020-01-31", "2021-01-31")) |> 
  pivot_wider(
    names_from = date,
    values_from = zori,
    names_prefix = "zori_"
 ) |> 
  mutate(
    drop = `zori_2020-01-31` - `zori_2021-01-31`
  ) |> 
  arrange(desc(drop)) |> 
  slice(1:10)

knitr::kable(covid_19)
```

| zip_code | county | neighborhood | zori_2020-01-31 | zori_2021-01-31 | drop |
|---:|:---|:---|---:|---:|---:|
| 10007 | New York | Lower Manhattan | 6334.211 | 5421.614 | 912.5966 |
| 10069 | New York | NA | 4623.042 | 3874.918 | 748.1245 |
| 10009 | New York | Lower East Side | 3406.442 | 2692.187 | 714.2550 |
| 10016 | New York | Gramercy Park and Murray Hill | 3731.135 | 3019.431 | 711.7045 |
| 10001 | New York | Chelsea and Clinton | 4108.098 | 3397.648 | 710.4499 |
| 10002 | New York | Lower East Side | 3645.416 | 2935.113 | 710.3028 |
| 10004 | New York | Lower Manhattan | 3149.658 | 2443.697 | 705.9608 |
| 10038 | New York | Lower Manhattan | 3573.201 | 2875.616 | 697.5853 |
| 10012 | New York | Greenwich Village and Soho | 3628.566 | 2942.344 | 686.2218 |
| 10010 | New York | Gramercy Park and Murray Hill | 3697.284 | 3012.353 | 684.9304 |

According to the table, we can see that compared with a year ago, these
ten regions have experienced major decline in zori values.
Coincidentally, the COVID-19 pandemic was affecting the US heavily.
Therefore, we can conclude that the COVID-19 pandemic was one of
significant factors that caused the decrease of zori values within a
year.
